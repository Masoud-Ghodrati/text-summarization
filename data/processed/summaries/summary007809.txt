Nick Bostrom: What would happen if machines surpassed human intellect?.
Bostrom: By 2050 we may have a 50/50 chance of achieving human-level A.I..
He says We want an A.I. that is safe and ethical, but it could get beyond our control.
Bostrom: Superintelligent machines could present major existential risks to humans.
